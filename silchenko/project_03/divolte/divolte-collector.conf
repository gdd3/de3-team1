divolte {
  global {
    server {
      host = 0.0.0.0
      port = 8290
    }
    kafka {
      // If true, flushing to Kafka is enabled.
      enabled = true

      // Number of threads to use for flushing events to Kafka
      threads = 2

      // The maximum queue of mapped events to buffer before
      // starting to drop new ones. Note that when this buffer is full,
      // events are dropped and a warning is logged. No errors are reported
      // to the source of the events. A single buffer is shared between all
      // threads, and its size will be rounded up to the nearest power of 2.
      buffer_size = 1048576

      // All settings in here are used as-is to configure
      // the Kafka producer.
      // See: http://kafka.apache.org/082/documentation.html#newproducerconfigs
      producer = {
        bootstrap.servers = ["instance-5.europe-west4-a.c.pro-signal-218407.internal:9092"]
        client.id = divolte.collector

        acks = 1
        retries = 0
        compression.type = none
        max.in.flight.requests.per.connection = 1
      }
    }
  }
  
  sinks {
    // The name of the sink. (It's referred to by the mapping.)
    kafka {
      type = kafka

      // This is the name of the topic that data will be produced on
      topic = user_event
    }
  }
  
  mappings {
    my_mapping = {
      schema_file = "/opt/divolte-collector-0.9.0/conf/user_event.avsc"
      mapping_script_file = "/opt/divolte-collector-0.9.0/conf/mapping_user_event.groovy"
      sources = [browser]
      sinks = [kafka]
    }
  }
  
  sources {
    browser {
      type = browser
    }
  }
}
